{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "collectible-round",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import math\n",
    "from collections import deque\n",
    "from ipywidgets import Output, HTML\n",
    "from Environment import Environment, PollutionModelEnvironment, EpidemicSpreadEnvironment\n",
    "from InformationModel import ScalarFieldInformationModel_stored_observation\n",
    "from Policy import GoToLocationPolicy, FollowPathPolicy, RandomWaypointPolicy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-ireland",
   "metadata": {},
   "source": [
    "# Robot class\n",
    "A class to gather the various functionalities of a robot (or drone) performing informative path planning. \n",
    "\n",
    "The robot has a current location including a height. It proceeds through a series of actions. Some actions (in the list ```everystep_actions```) are executed always, while the ```pending_actions``` list is the one which is added by the policy. Actions include movement action, actions that directly set the location, velocity and acceleration, as well as actions for observation. There are some simplified actions like ```north''', ```west``` etc.\n",
    "\n",
    "The execution of the robot proceeds through timesteps, which are at a time delta_t from the previous timestep. At each timestep there are two phases:\n",
    "* ```enact_policy```: the policies associated with the robot are called and have the ability to schedule actions for execution \n",
    "* ```proceed```: actions are executed. The actions (in the list ```everystep_actions```) are executed always, while the ```pending_actions``` list is the one which is added by the policy, and are cleared at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "higher-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Robot:\n",
    "    \"\"\"The representation of a robot / drone.\"\"\"    \n",
    "    \n",
    "    def __init__(self, name, init_x, init_y, init_altitude, grid_resolution=1, env=None, im=None):\n",
    "        self.name = name\n",
    "        self.init_x, self.init_y, self.init_altitude = init_x, init_y, init_altitude        \n",
    "        self.x, self.y, self.altitude = init_x, init_y, init_altitude\n",
    "        self.vel_x = self.vel_y = self.vel_altitude = 0\n",
    "        # actions requested at a particular timestep\n",
    "        self.pending_actions = []\n",
    "        if env == None:\n",
    "            self.everystep_actions = [\"Move\", \"History\"]\n",
    "        else:\n",
    "            self.everystep_actions = [\"Move\", \"Observe\", \"History\"]\n",
    "        self.grid_resolution = grid_resolution\n",
    "        self.energy = 100 # energy level\n",
    "        self.value = 0 # accumulated value\n",
    "        self.location_history = deque()\n",
    "        self.policy = None\n",
    "        self.env = env\n",
    "        self.im = im\n",
    "    \n",
    "        \n",
    "    def add_action(self, action):\n",
    "        \"\"\"Sets a pending action: normally this means to move. \"\"\"\n",
    "        self.pending_actions.append(action)\n",
    "\n",
    "        \n",
    "    def enact_policy(self, delta_t = 1.0):\n",
    "        \"\"\"Call the policy, if any to schedule actions\"\"\"\n",
    "        if self.policy != None:\n",
    "            self.policy.act(delta_t)\n",
    "        \n",
    "        \n",
    "    def proceed(self, delta_t = 1.0):\n",
    "        \"\"\"Enacts all the pending and everystep actions.\n",
    "        Updates the energy and value accumulated\"\"\"\n",
    "        for action in self.pending_actions:\n",
    "                self.enact_action(action, delta_t)\n",
    "        self.pending_actions = []\n",
    "        for action in self.everystep_actions:\n",
    "                self.enact_action(action, delta_t)\n",
    "\n",
    "        \n",
    "    def enact_action(self, action, delta_t = 1.0):\n",
    "        \"\"\"Enacts one pending action. We are allowing here for a couple of shorthand\n",
    "        actions like east, west, south, north...\"\"\"\n",
    "        if action == \"Observe\":\n",
    "            # simple point observation, skip it if we are outside the environment\n",
    "            try:\n",
    "                reading = self.env.value[int(self.x),int(self.y)]\n",
    "            except IndexError:\n",
    "                return\n",
    "            obs = {\"x\": self.x, \"y\": self.y, \"value\": reading}\n",
    "            self.im.add_observation(obs)\n",
    "            self.energy = self.energy - 1\n",
    "            # FIXME: this should be the VoI\n",
    "            self.value = self.value + 1\n",
    "            return\n",
    "        if action == \"Move\":\n",
    "            self.x = self.x + delta_t * self.vel_x\n",
    "            self.y = self.y + delta_t * self.vel_y\n",
    "            self.altitude = self.altitude + delta_t * self.vel_altitude\n",
    "            return\n",
    "        if action == \"History\": # appends x, y, altitude \n",
    "            self.location_history.appendleft([self.x, self.y, self.altitude])\n",
    "            return\n",
    "        if action == \"West\":\n",
    "            self.vel_x = - self.grid_resolution\n",
    "            self.vel_y = 0\n",
    "            self.vel_altitude = 0\n",
    "            return\n",
    "        if action == \"East\":\n",
    "            self.vel_x = self.grid_resolution\n",
    "            self.vel_y = 0\n",
    "            self.vel_altitude = 0\n",
    "            return\n",
    "        if action == \"North\": # this is the opposite of what one would think due to coord system\n",
    "            self.vel_x = 0\n",
    "            self.vel_y = -self.grid_resolution\n",
    "            self.vel_altitude = 0\n",
    "            return\n",
    "        if action == \"South\": # this is the opposite of what one would think due to coord system\n",
    "            self.vel_x = 0\n",
    "            self.vel_y = self.grid_resolution\n",
    "            self.vel_altitude = 0\n",
    "            return\n",
    "        if action[0:4] == \"loc \":\n",
    "            params = ast.literal_eval(action[4:])\n",
    "            self.x = params[0]\n",
    "            self.y = params[1]\n",
    "            if len(params) > 2:\n",
    "                self.altitude = params[2]\n",
    "            return\n",
    "        if action[0:4] == \"vel \":\n",
    "            params = ast.literal_eval(action[4:])\n",
    "            self.vel_x = params[0]\n",
    "            self.vel_y = params[1]\n",
    "            if len(params) > 2:\n",
    "                self.vel_altitude = params[2]\n",
    "            return\n",
    "        if action[0:4] == \"acc \":\n",
    "            params = ast.literal_eval(action[4:])\n",
    "            self.vel_x = self.vel_x + delta_t * params[0]\n",
    "            self.vel_y = self_vel_y + delta_t * params[1]\n",
    "            if len(params) > 2:\n",
    "                self.vel_altitude = self.vel_altitude + delta_t * params[2]\n",
    "            return    \n",
    "        \n",
    "        ## FIXME: add an action for ascend, descend, observe\n",
    "        raise Exception(f\"Unsupported action {action} for robot {self.name}\")\n",
    "        \n",
    "        \n",
    "    def toHTML(self):\n",
    "        \"\"\"Simple HTML formatting\"\"\"\n",
    "        value = f\"<b>{self.name}</b><br/> loc = [x:{self.x:.2f},y:{self.y:.2f}, alt:{self.altitude:.2f}]<br/>\" + \\\n",
    "            f\"vel = [x:{self.vel_x:.2f},y:{self.vel_y:.2f},alt:{self.vel_altitude:.2f}]\" \n",
    "        value += \"<br>Policy: \"\n",
    "        if self.policy == None:\n",
    "            value += \"None\"\n",
    "        else: \n",
    "            value += str(self.policy)\n",
    "        value += \"<br>Pending actions:\"\n",
    "        value += str(self.pending_actions)\n",
    "        return value\n",
    "            \n",
    "    def __str__(self):\n",
    "        \"\"\"Simple text formatting\"\"\"\n",
    "        value = f\"{self.name} --> loc = [x:{self.x:.2f},y:{self.y:.2f},alt:{self.altitude:.2f}] \" + \\\n",
    "            f\"vel = [x:{self.vel_x:.2f},y:{self.vel_y:.2f},alt:{self.vel_altitude:.2f}]\" \n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-theme",
   "metadata": {},
   "source": [
    "## Testing the robot class for sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "informal-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = PollutionModelEnvironment(\"water\", 100, 100, seed=1)\n",
    "env.evolve_speed = 1\n",
    "env.p_pollution = 0.1\n",
    "for t in range(90):\n",
    "    env.proceed()\n",
    "im = ScalarFieldInformationModel_stored_observation(\"sample\", env.width, env.height, estimation_type=\"disk-fixed\", estimation_radius=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "anonymous-pearl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robi --> loc = [x:20.00,y:30.00,alt:0.00] vel = [x:0.00,y:0.00,alt:0.00]\n",
      "Robi --> loc = [x:20.00,y:29.00,alt:0.00] vel = [x:0.00,y:-1.00,alt:0.00]\n"
     ]
    }
   ],
   "source": [
    "robot = Robot(\"Robi\", 20, 30, 0)\n",
    "robot.env = env\n",
    "robot.im = im\n",
    "# print(vars(robot))\n",
    "print(robot)\n",
    "robot.add_action(\"North\")\n",
    "robot.enact_policy()\n",
    "robot.proceed()\n",
    "print(robot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "alternative-seeking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>Robi</b><br/> loc = [x:3.14,y:29.00, alt:0.00]<br/>vel = [x:0.00,y:-1.00,alt:0.00]<br>Policy: None<br>Pending actions:[]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7036e98e5f4c70a4b5484f9d5bd613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Robi</b><br/> loc = [x:3.14,y:29.00, alt:0.00]<br/>vel = [x:0.00,y:-1.00,alt:0.00]<br>Policy: N…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "robot.x = math.pi\n",
    "print(robot.toHTML())\n",
    "HTML(\n",
    "    value=robot.toHTML(),\n",
    "    placeholder='Some HTML',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "surprised-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pi = 3.14'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Pi = {math.pi:.2f}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "flying-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque([[20.0, 29.0, 0.0]])\n"
     ]
    }
   ],
   "source": [
    "print(robot.location_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2439ef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "robot.policy = FollowPathPolicy(None, robot, 1, [[0,0], [5, 5], [9,0]], repeat = True)\n",
    "\n",
    "\n",
    "value = robot.toHTML()\n",
    "value += \"<br>Policy: \"\n",
    "if robot.policy == None:\n",
    "    value += \"None\"\n",
    "else: \n",
    "    value += str(robot.policy)\n",
    "value += \"<br>Pending actions:\"\n",
    "value += str(robot.pending_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "according-halifax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e7f250e95f44b7af0a6de97de33fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<b>Robi</b><br/> loc = [x:3.14,y:29.00, alt:0.00]<br/>vel = [x:0.00,y:-1.00,alt:0.00]<br>Policy: <…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HTML(\n",
    "    value=value,\n",
    "    placeholder='Some HTML',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cardiovascular-maine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'FollowPathPolicy',\n",
       " 'env': None,\n",
       " 'robot': <__main__.Robot at 0x7fca88b76ee0>,\n",
       " 'waypoints': [[0, 0], [5, 5], [9, 0]],\n",
       " 'vel': 1,\n",
       " 'currentwaypoint': 0,\n",
       " 'repeat': True}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(robot.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "italian-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "if env == None:\n",
    "    self.everystep_actions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-settle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-township",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
